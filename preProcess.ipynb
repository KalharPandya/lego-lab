{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Block 1: Environment and Imports Check\n",
    "# =============================================================================\n",
    "print(\"OpenCV Version:\", cv2.__version__)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available(), torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"No GPU detected.\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Block 2: Image Processing (Caching Processed Images)\n",
    "# =============================================================================\n",
    "# Define directories for raw and processed images\n",
    "raw_images_dir = r\"lego_dataset\\dataset_20210629145407_top_600\\images\"\n",
    "processed_images_dir = r\"output\"\n",
    "os.makedirs(processed_images_dir, exist_ok=True)\n",
    "\n",
    "# Check if processed images already exist (assume at least one file exists)\n",
    "processed_files = glob.glob(os.path.join(processed_images_dir, \"*.jpg\"))\n",
    "if len(processed_files) > 0:\n",
    "    print(f\"Processed images already exist in {processed_images_dir} (found {len(processed_files)} files). Skipping processing.\")\n",
    "else:\n",
    "    print(\"No processed images found. Processing raw images now...\")\n",
    "    # Example parameters for mean shift filtering\n",
    "    sp1, sr1 = 10, 30\n",
    "    sp2, sr2 = 10, 40\n",
    "    target_size = (224, 224)\n",
    "\n",
    "    def process_and_save(image_path, output_dir, target_size=(224,224)):\n",
    "        try:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"Warning: Unable to load {image_path}\")\n",
    "                return\n",
    "            resized = cv2.resize(image, target_size)\n",
    "            # Convert to HSV and apply mean shift filtering twice\n",
    "            image_hsv = cv2.cvtColor(resized, cv2.COLOR_BGR2HSV)\n",
    "            segmented_hsv = cv2.pyrMeanShiftFiltering(image_hsv, sp=sp1, sr=sr1)\n",
    "            segmented_hsv = cv2.pyrMeanShiftFiltering(segmented_hsv, sp=sp2, sr=sr2)\n",
    "            # Convert back to BGR\n",
    "            final_image = cv2.cvtColor(segmented_hsv, cv2.COLOR_HSV2BGR)\n",
    "            output_path = os.path.join(output_dir, os.path.basename(image_path))\n",
    "            cv2.imwrite(output_path, final_image)\n",
    "            return output_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    raw_image_files = glob.glob(os.path.join(raw_images_dir, \"*.jpg\"))\n",
    "    pbar = tqdm(raw_image_files, desc=\"Processing images\", unit=\"file\")\n",
    "    for img_path in pbar:\n",
    "        process_and_save(img_path, processed_images_dir, target_size=target_size)\n",
    "    processed_files = glob.glob(os.path.join(processed_images_dir, \"*.jpg\"))\n",
    "    print(f\"Processed and saved {len(processed_files)} images to {processed_images_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Block 3: Dataset Splitting (Train/Val/Test)\n",
    "# =============================================================================\n",
    "split_dir = r\"output_split\"\n",
    "train_dir = os.path.join(split_dir, \"train\")\n",
    "val_dir = os.path.join(split_dir, \"val\")\n",
    "test_dir = os.path.join(split_dir, \"test\")\n",
    "for d in [train_dir, val_dir, test_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Check if dataset has already been split (e.g., check if train_dir has files)\n",
    "train_files = glob.glob(os.path.join(train_dir, \"*.jpg\"))\n",
    "if len(train_files) > 0:\n",
    "    print(f\"Dataset already split (found {len(train_files)} train images). Skipping splitting.\")\n",
    "else:\n",
    "    print(\"Splitting dataset into train/val/test...\")\n",
    "    all_files = glob.glob(os.path.join(processed_images_dir, \"*.jpg\"))\n",
    "    train_val_files, test_files = train_test_split(all_files, test_size=0.2, random_state=42)\n",
    "    train_files, val_files = train_test_split(train_val_files, test_size=0.2, random_state=42)\n",
    "    print(f\"Train: {len(train_files)} images\")\n",
    "    print(f\"Validation: {len(val_files)} images\")\n",
    "    print(f\"Test: {len(test_files)} images\")\n",
    "    def copy_files(file_list, target_dir):\n",
    "        for file_path in tqdm(file_list, desc=f\"Copying to {os.path.basename(target_dir)}\", unit=\"file\"):\n",
    "            shutil.copy2(file_path, os.path.join(target_dir, os.path.basename(file_path)))\n",
    "    copy_files(train_files, train_dir)\n",
    "    copy_files(val_files, val_dir)\n",
    "    copy_files(test_files, test_dir)\n",
    "    print(\"Dataset split and files copied successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Block 4: XML Annotation Processing and Caching\n",
    "# =============================================================================\n",
    "# We cache annotation counts to a file so we don't reprocess every time.\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xml_cache_file = \"annotation_counts.npy\"\n",
    "annotations_dir = r\"lego_dataset\\dataset_20210629145407_top_600\\annotations\"\n",
    "if os.path.exists(xml_cache_file):\n",
    "    print(f\"Loading cached annotation counts from {xml_cache_file}...\")\n",
    "    data = np.load(xml_cache_file, allow_pickle=True).item()\n",
    "    counts, piece_counts = data['counts'], data['piece_counts']\n",
    "else:\n",
    "    print(\"Processing XML annotation files...\")\n",
    "    xml_files = glob.glob(os.path.join(annotations_dir, \"*.xml\"))\n",
    "    counts = {}\n",
    "    piece_counts = []\n",
    "    def parse_xml_file(xml_file):\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            object_count = len(root.findall(\"object\"))\n",
    "            filename = os.path.basename(xml_file)\n",
    "            return filename, object_count\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {executor.submit(parse_xml_file, xml_file): xml_file for xml_file in xml_files}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing XML files\"):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                filename, count = result\n",
    "                counts[filename] = count\n",
    "                piece_counts.append(count)\n",
    "    np.save(xml_cache_file, {'counts': counts, 'piece_counts': piece_counts})\n",
    "    print(f\"Annotation counts cached to {xml_cache_file}\")\n",
    "\n",
    "print(\"LEGO pieces per image (by filename):\")\n",
    "for filename, count in counts.items():\n",
    "    print(f\"{filename}: {count} pieces\")\n",
    "total_objects = np.sum(piece_counts)\n",
    "print(\"\\nTotal number of LEGO pieces in dataset:\", total_objects)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(piece_counts, bins=np.arange(0, max(piece_counts) + 2) - 0.5, edgecolor='black')\n",
    "plt.xlabel(\"Number of LEGO pieces per image\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of LEGO Pieces per Image\")\n",
    "plt.xticks(range(0, max(piece_counts) + 1))\n",
    "plt.show()\n"
   ]
  },